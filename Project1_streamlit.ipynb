{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21024,"status":"ok","timestamp":1733586398422,"user":{"displayName":"Trúc Lê Thị Thanh","userId":"01544266926041133552"},"user_tz":-420},"id":"7lHOldWDGy1Y","outputId":"05b8c2fc-dd4a-4f93-f251-9c28d17f2018"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install streamlit -q"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6kkdWpJuG7PS"},"outputs":[],"source":["!pip install pyngrok -q"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ixTx1I_O1E1a","executionInfo":{"status":"ok","timestamp":1733586443278,"user_tz":-420,"elapsed":38620,"user":{"displayName":"Trúc Lê Thị Thanh","userId":"01544266926041133552"}},"outputId":"be4682ce-c322-4177-bc4b-8b880801a142"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","/content/gdrive/MyDrive/DL07_k299_LeThiThanhTruc/Cung_cap_HV\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","%cd '/content/gdrive/MyDrive/DL07_k299_LeThiThanhTruc/Cung_cap_HV'"]},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"ARApU8DvUCwc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = pd.read_csv('data/Danh_gia.csv')"],"metadata":{"id":"sGFk0TCownn3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv('data/processed_data.csv')\n","df = df[['noi_dung_binh_luan','thai_do']]"],"metadata":{"id":"xKdI98T3BpbE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.fillna('trống', inplace=True)"],"metadata":{"id":"BL3j9z8MCRv6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from PIL import Image\n","image = Image.open('background.jpg')"],"metadata":{"id":"oFOAdkSL5n3P"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":73,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1733593160619,"user":{"displayName":"Trúc Lê Thị Thanh","userId":"01544266926041133552"},"user_tz":-420},"id":"5w3uQrzogQBp","outputId":"59d8a259-d473-4fb3-fd02-ce0642e321e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting app.py\n"]}],"source":["# GUI\n","%%writefile app.py\n","import pickle\n","import streamlit as st\n","\n","import pandas as pd\n","import wordcloud as wc\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n","from sklearn.svm import LinearSVC\n","from sklearn.utils.class_weight import compute_class_weight\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from PIL import Image\n","import base64\n","\n","st.set_page_config(\n","   page_title=\"Ex-stream-ly Cool App\",\n","   page_icon=\"🧊\",\n","   layout=\"wide\",\n","   initial_sidebar_state=\"expanded\",\n",")\n","\n","def get_base64_of_bin_file(bin_file):\n","     with open(bin_file, 'rb') as f:\n","         data = f.read()\n","     return base64.b64encode(data).decode()\n","\n","#\n","def set_png_as_page_bg(png_file):\n","     bin_str = get_base64_of_bin_file(png_file)\n","     page_bg_img = '''\n","     <style>\n","     .stApp {\n","     background-image: url(\"data:image/png;base64,%s\");\n","     background-size: cover;\n","     }\n","     </style>\n","     ''' % bin_str\n","\n","     st.markdown(page_bg_img, unsafe_allow_html=True)\n","     return\n","\n","set_png_as_page_bg('background.jpg')\n","\n","st.sidebar.image('logo_hasaki.jpg', use_container_width=True)\n","\n","st.title(\"HASAKI\")\n","st.write(\"## Sentiment Analysis - Review\")\n","menu = [\"Business Objective\", \"Build Project\", \"New Prediction\"]\n","choice = st.sidebar.selectbox('Menu',menu)\n","st.sidebar.markdown(\"\"\"---\"\"\")\n","st.sidebar.title(\"Thành viên thực hiện:\")\n","st.sidebar.markdown(\n","    \"\"\"\n","    :blue[**Bùi Văn Bình**]\\t:man:\n","    \\n\\n\n","    :blue[**Lê Thị Thanh Trúc**]\\t:woman:\n","    \"\"\")\n","st.sidebar.write(\"\"\"#### Giảng viên hướng dẫn:\n","                  Phương Khuất Thùy\"\"\")\n","st.sidebar.write(\"\"\"#### Thời gian thực hiện:\n","                  12/2024\"\"\")\n","if choice == 'Business Objective':\n","    st.subheader(\"Business Objective\")\n","    st.write(\"\"\"\n","    ###### Sentiment Analysis - Phân tích tình cảm\n","    \"\"\")\n","    st.write(\"\"\"###### Problem/ Requirement: Ứng dụng Sentiment Analysis - phân tích tình cảm để phân tích đánh giá người dùng về sản phẩm kinh doanh của HASAKI từ đó hiểu rõ khách hàng và cải thiện chất lượng sản phẩm\"\"\")\n","\n","elif choice == 'Build Project':\n","    st.subheader(\"Build Project\")\n","    st.write(\"##### 1. Nội dung đánh giá\")\n","    with open('data/Danh_gia.csv', 'r') as file:\n","        data = pd.read_csv(file)\n","    data.fillna('trống', inplace=True)\n","    st.dataframe(data[['ma_san_pham','noi_dung_binh_luan','so_sao']].head(10))\n","    st.write(\"##### Data preprocessing:\")\n","    with open('data/processed_data.csv', 'r') as file:\n","        df = pd.read_csv(file)\n","    df.fillna('trống', inplace=True)\n","    st.dataframe(df[['ma_san_pham','noi_dung_binh_luan','thai_do']].head(10))\n","\n","    st.write(\"##### 2. Visualize\")\n","    st.write(\"Số sao:\")\n","    fig0 = sns.countplot(data=data[['so_sao']], x='so_sao')\n","    st.pyplot(fig0.figure)\n","    #st.write(\"Thái độ:\")\n","    #fig1 = sns.countplot(data=df[['thai_do']], x='thai_do')\n","    #st.pyplot(fig1.figure)\n","\n","    st.write(\"##### 3. Build RandomForest Model: ...\")\n","    pkl_filename = \"model.pkl\"\n","    #pkl_vectorizer = \"vectorizer_model.pkl\"\n","    # import pickle\n","    with open(pkl_filename, 'rb') as file:\n","        rf_model = pickle.load(file)\n","    # doc model vectorize\n","    #with open(pkl_vectorizer, 'rb') as file:\n","        #vectorizer_model = pickle.load(file)\n","    thai_do_dict = {'positive':1, 'negative':0}\n","    df['thai_do'] = df['thai_do'].map(thai_do_dict)\n","    X_train, X_test, y_train, y_test = train_test_split(df['noi_dung_binh_luan'], df['thai_do'], test_size=0.2, random_state=42, stratify=df['thai_do'])\n","\n","    class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n","    class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n","    vectorizer = TfidfVectorizer(max_features=500)\n","    X_train_vectorized = vectorizer.fit_transform(X_train)\n","    X_test_vectorized = vectorizer.transform(X_test)\n","\n","    score_train = rf_model.score(X_train_vectorized, y_train)\n","    score_test = rf_model.score(X_test_vectorized, y_test)\n","\n","    y_pred = rf_model.predict(X_test_vectorized)\n","    y_prob = rf_model.predict_proba(X_test_vectorized)\n","\n","    acc = accuracy_score(y_test, y_pred)\n","    cm = confusion_matrix(y_test, y_pred)\n","    cr = classification_report(y_test, y_pred)\n","    roc = roc_auc_score(y_test, y_prob[:, 1])\n","\n","    st.write(\"##### 4. Evaluation\")\n","    st.code(\"Score train:\"+ str(round(score_train,2)) + \" vs Score test:\" + str(round(score_test,2)))\n","    st.code(\"Accuracy:\"+str(round(acc,2)))\n","    st.write(\"###### Confusion matrix:\")\n","    st.code(cm)\n","    fig2 = sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n","    st.pyplot(fig2.figure)\n","    st.write(\"###### Classification report:\")\n","    st.code(cr)\n","    st.code(\"Roc AUC score:\" + str(round(roc,2)))\n","\n","    # calculate roc curve\n","    st.write(\"###### ROC curve\")\n","    fpr, tpr, thresholds = roc_curve(y_test, y_prob[:, 1])\n","    fig, ax = plt.subplots()\n","    ax.plot([0, 1], [0, 1], linestyle='--')\n","    ax.plot(fpr, tpr, marker='.')\n","    st.pyplot(fig)\n","\n","    st.write(\"##### 5. Summary: This model is good for sentiment analysis.\")\n","\n","elif choice == 'New Prediction':\n","    st.subheader(\"Select data\")\n","    flag = False\n","    lines = None\n","    type = st.radio(\"Upload data or Input data?\", options=(\"Upload\", \"Input\"))\n","    if type==\"Upload\":\n","        # Upload file\n","        uploaded_file_1 = st.file_uploader(\"Choose a file\", type=['txt', 'csv'])\n","        if uploaded_file_1 is not None:\n","            lines = pd.read_csv(uploaded_file_1, header=None)\n","            st.dataframe(lines)\n","            lines = lines[0]\n","            flag = True\n","    if type==\"Input\":\n","        content = st.text_area(label=\"Input your content:\")\n","        if content!=\"\":\n","            lines = np.array([content])\n","            flag = True\n","\n","    if flag:\n","        st.write(\"Content:\")\n","        if len(lines)>0:\n","            st.code(lines)\n","            vectorizer = TfidfVectorizer(max_features=500)\n","            x_new = vectorizer.transform(lines)\n","            pkl_filename = \"model.pkl\"\n","            with open(pkl_filename, 'rb') as file:\n","                rf_model = pickle.load(file)\n","            y_pred_new = rf_model.predict(x_new)\n","            st.code(\"New predictions (0: Positive, 1: Negative): \" + str(y_pred_new))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P1iIfBH0HPUt"},"outputs":[],"source":["from pyngrok import ngrok"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1711,"status":"ok","timestamp":1733586447473,"user":{"displayName":"Trúc Lê Thị Thanh","userId":"01544266926041133552"},"user_tz":-420},"id":"wDwYKukfHS0u","outputId":"decba674-5045-43a4-c9d0-8f4ad92415e0"},"outputs":[{"output_type":"stream","name":"stdout","text":[]}],"source":["ngrok.set_auth_token(\"2psrMI41Zga88RmKeaU9tTzM1Lx_3z2DY1jg9y1VkrUcAqpnm\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1102,"status":"ok","timestamp":1733586448571,"user":{"displayName":"Trúc Lê Thị Thanh","userId":"01544266926041133552"},"user_tz":-420},"id":"ybUrMTnXHWvg","outputId":"3d558cc2-2312-47e2-b167-c6a6fd05f635"},"outputs":[{"output_type":"stream","name":"stdout","text":["nohup: appending output to 'nohup.out'\n"," * Tunnel URL: https://8fd3-34-73-235-159.ngrok-free.app\n"]}],"source":["# Start Streamlit server on a specific port\n","!nohup streamlit run app.py --server.port 8501 &\n","\n","# Start ngrok tunnel to expose the Streamlit server\n","ngrok_tunnel = ngrok.connect(addr='8501', proto='http', bind_tls=True)\n","\n","# Print the URL of the ngrok tunnel\n","print(' * Tunnel URL:', ngrok_tunnel.public_url)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5I0zTn6YKDLB"},"outputs":[],"source":["#ngrok.kill()"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMxNZlpJhu2tqmU6QACdp7q"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}